{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koiketomoya/.pyenv/versions/anaconda3-5.1.0/envs/kaggle/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.3567 - val_loss: 0.2709\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2635 - val_loss: 0.2523\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2424 - val_loss: 0.2306\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2229 - val_loss: 0.2128\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2075 - val_loss: 0.1995\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1959 - val_loss: 0.1894\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1871 - val_loss: 0.1819\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1802 - val_loss: 0.1758\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1746 - val_loss: 0.1705\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1696 - val_loss: 0.1658\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1650 - val_loss: 0.1615\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.1609 - val_loss: 0.1575\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1571 - val_loss: 0.1538\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1536 - val_loss: 0.1505\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1504 - val_loss: 0.1473\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1473 - val_loss: 0.1444\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1444 - val_loss: 0.1415\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1417 - val_loss: 0.1388\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1391 - val_loss: 0.1363\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1366 - val_loss: 0.1338\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1343 - val_loss: 0.1316\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1321 - val_loss: 0.1294\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1300 - val_loss: 0.1273\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1279 - val_loss: 0.1254\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1260 - val_loss: 0.1234\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1241 - val_loss: 0.1216\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1224 - val_loss: 0.1199\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1207 - val_loss: 0.1183\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1192 - val_loss: 0.1168\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1178 - val_loss: 0.1154\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1164 - val_loss: 0.1142\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1152 - val_loss: 0.1130\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1141 - val_loss: 0.1119\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1130 - val_loss: 0.1109\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1121 - val_loss: 0.1099\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1112 - val_loss: 0.1091\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.1104 - val_loss: 0.1083\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1096 - val_loss: 0.1076\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1089 - val_loss: 0.1069\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1083 - val_loss: 0.1063\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1077 - val_loss: 0.1057\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1071 - val_loss: 0.1052\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1066 - val_loss: 0.1047\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1061 - val_loss: 0.1042\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1056 - val_loss: 0.1038\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.1051 - val_loss: 0.1033\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1047 - val_loss: 0.1029\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1043 - val_loss: 0.1026\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1040 - val_loss: 0.1022\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1036 - val_loss: 0.1019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181c098358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18333e7cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3288 - val_loss: 0.2624\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2562 - val_loss: 0.2483\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2389 - val_loss: 0.2275\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2137 - val_loss: 0.2036\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1975 - val_loss: 0.1924\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1864 - val_loss: 0.1831\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1790 - val_loss: 0.1762\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1736 - val_loss: 0.1702\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1688 - val_loss: 0.1665\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1637 - val_loss: 0.1598\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1595 - val_loss: 0.1558\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1557 - val_loss: 0.1524\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1526 - val_loss: 0.1497\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1499 - val_loss: 0.1482\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1474 - val_loss: 0.1463\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1449 - val_loss: 0.1437\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1426 - val_loss: 0.1417\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1401 - val_loss: 0.1423\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1381 - val_loss: 0.1348\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1362 - val_loss: 0.1330\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1344 - val_loss: 0.1326\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1329 - val_loss: 0.1314\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1312 - val_loss: 0.1285\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1297 - val_loss: 0.1286\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1284 - val_loss: 0.1271\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1273 - val_loss: 0.1247\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1263 - val_loss: 0.1241\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1251 - val_loss: 0.1229\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1241 - val_loss: 0.1214\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1233 - val_loss: 0.1213\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1223 - val_loss: 0.1208\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1214 - val_loss: 0.1180\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1206 - val_loss: 0.1184\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1200 - val_loss: 0.1174\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1193 - val_loss: 0.1172\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1187 - val_loss: 0.1170\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1181 - val_loss: 0.1172\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1174 - val_loss: 0.1174\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1169 - val_loss: 0.1152\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1163 - val_loss: 0.1151\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1157 - val_loss: 0.1145\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1150 - val_loss: 0.1127\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1145 - val_loss: 0.1131\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1140 - val_loss: 0.1124\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1133 - val_loss: 0.1122\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1129 - val_loss: 0.1122\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1124 - val_loss: 0.1117\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1117 - val_loss: 0.1099\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1115 - val_loss: 0.1111\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1110 - val_loss: 0.1080\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1106 - val_loss: 0.1087\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1101 - val_loss: 0.1081\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1098 - val_loss: 0.1087\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1093 - val_loss: 0.1072\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1089 - val_loss: 0.1074\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1086 - val_loss: 0.1076\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1083 - val_loss: 0.1070\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1080 - val_loss: 0.1059\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1076 - val_loss: 0.1066\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1074 - val_loss: 0.1076\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1069 - val_loss: 0.1058\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1068 - val_loss: 0.1078\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1065 - val_loss: 0.1073\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1062 - val_loss: 0.1056\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1057 - val_loss: 0.1037\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1055 - val_loss: 0.1041\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1053 - val_loss: 0.1066\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1050 - val_loss: 0.1063\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1047 - val_loss: 0.1039\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1045 - val_loss: 0.1034\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1043 - val_loss: 0.1056\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1040 - val_loss: 0.1023\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1039 - val_loss: 0.1020\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1036 - val_loss: 0.1041\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1034 - val_loss: 0.1018\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1031 - val_loss: 0.1017\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1029 - val_loss: 0.1033\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1027 - val_loss: 0.1019\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1025 - val_loss: 0.1011\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1024 - val_loss: 0.1025\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1023 - val_loss: 0.1014\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1019 - val_loss: 0.1010\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1018 - val_loss: 0.1013\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1014 - val_loss: 0.1001\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1013 - val_loss: 0.0992\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1011 - val_loss: 0.0997\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1009 - val_loss: 0.1005\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1007 - val_loss: 0.1006\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.1006 - val_loss: 0.1001\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1004 - val_loss: 0.0995\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1004 - val_loss: 0.0989\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1000 - val_loss: 0.0997\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0999 - val_loss: 0.1003\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0998 - val_loss: 0.0980\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0996 - val_loss: 0.1002\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0996 - val_loss: 0.0979\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0993 - val_loss: 0.0983\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0990 - val_loss: 0.0981\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0989 - val_loss: 0.0992\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0989 - val_loss: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1833c387b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-d252ebf52f78>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-d252ebf52f78>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=/tmp/autoencoder\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir=/tmp/autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape(4, 4 * 8).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]]) * epsilon_std\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
